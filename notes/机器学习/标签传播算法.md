# 标签传播算法(Label Propagation)

标签传播算法（label propagation）的核心思想：相似的数据应该具有相同的label。LP算法包括两大步骤：
1. 构造相似矩阵
2. 迭代进行标签传播

## 1.1 构造相似矩阵

LP算法基于Graph，因此我们可以以每一个数据点为节点建立图，包括Labeled和unlabeled数据。以节点之间的边表示节点间的相似度。以全连接图为例，节点之间的边权为：
$$
w_{ij} = \exp({-\frac{||x_i-x_j||^2}{\alpha^2}})
$$
其中，$α$为超参数。

还可以通过KNN构图，只保留每个节点的k近邻权重，其他为0，代表边不存在，因此是稀疏相似矩阵。

## 2.2 LP算法

LP算法通过节点之间的边传播Label，边权越大，两节点越相似，那么Label越容易传播过去，定义一个N×N的概率转移矩阵P:
$$
P_{ij} = P(i\rightarrow j)= \frac{w_{ij}}{\sum_{k = 1}^{n}w_{ik}}
$$
$P_{ij}$表示Label从节点i传播到节点j的概率。

假设有C个类和L个labeled样本，定义一个`LxC的label矩阵$Y_L$`，第i行表示第i个样本的标签指示向量，即如果第i个样本的类别是j，那么该行的第j个元素为1，其他为0。同样，我们也给U个unlabeled样本一个`UxC的label矩阵YU`。把他们合并，我们得到一个`NxC的soft label矩阵F=[$Y_L$;YU]`。soft label的意思是，我们保留样本i属于每个类别的概率，而不是互斥性的，这个样本以概率1只属于一个类。最后确定这个样本i的类别的时候，是取max也就是概率最大的那个类作为它的类别的。由于YU在最开始无法确定，可以赋初值为任意值。

LP算法步骤如下：
1. 执行传播：F=PF
2. 重置F中labeled样本的标签：$F_L$=$Y_L$
3. 重复步骤1，2直到F收敛

> 步骤1：就是将矩阵P和矩阵F相乘，每个节点都将自己的label以P确定的概率传播给其他节点。如果两个节点越相似（在欧式空间中距离越近），那么对方的label就越容易被自己的label赋予，
>
> 步骤2:：由于labeled数据的label是事先确定的，所以每次传播完，它都得回归它本来的label。随着labeled数据不断的将自己的label传播出去，最后的类边界会穿越高密度区域，而停留在低密度的间隔中。

## LP算法的改进

由于$Y_L$已知，因此可以对P进行划分：
$$
P = \left[
\begin{matrix}
P_{LL}&P_{LU}\\
P_{UL}&P_{UU}
\end{matrix}
\right]
$$
因此算法简化为计算：
$$
f_{U} = P_{UU}Y_U + Y_LP_{LU}
$$
可以证明该式存在一个凸解：
$$
f_{U} = (I - P_{UU})^{-1}P_{UL}Y_{L}
$$


转载于https://blog.csdn.net/zouxy09/article/details/49105265

参考文献：

https://www.arocmag.com/article/01-2013-01-004.html

