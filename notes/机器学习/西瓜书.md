# 西瓜书

# 1. 绪论

## 1.1 基本术语

**数据集**(data set)： 所有数据的集合

**示例/样本**(instance/sample): 一行数据，关于一个事件或对象的描述

**属性/特征**(attribute/feature)： 描述事物的某一性质

**属性值**(attribute value)： 一个特征可能的取值

**属性空间/样本空间**(attribute/sample space)： 所有特征构成的空间

**特征向量**(feature vector): 一个样本的向量表示形式

**维数**(dimensionality)：样本的特征个数

**标记**(label)： 样本的标签值

**假设**(hypothesis)： 从数据中学得模型的过程叫做学习(learning), 模型对应了数据的某种规律，所以模型也称为假设

**训练集**(training set)：训练模型使用的数据集

**测试集**(testing set)：用训练集训练处模型后，被预测的样本叫测试集/测试样本

**分类**(classification)： 预测离散值

**回归**(regression)： 预测连续值

**监督学习**(supervised learning)： 有标记信息，比如分类和回归

**无监督学习**(unsupervised learning)：无标记信息，比如聚类

**泛化能力**(generalization)： 最终得到的模型适用于新样本的能力.

## 1.2 假设空间

假设空间即所有假设组成的空间，我们可以把学习过程看作一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集"匹配"的假设，即能够将训练集判断正确的假设.假设的表示一旦确定，假设空间的大小就确定了.即：`满足特定标签值的所有特征向量组成的空间`

## 1.3 归纳偏好

上面提到了得到的假设集合在新样本中可能是相互冲突的，如何取舍(换句话说，算法对某种类型假设的偏好)，被称为归纳偏好.

所有的机器学习算法都有其归纳偏好的.

目前有两种一般性的原则来引导算法确立"正确"的偏好：

1. 奥卡姆剃刀原则(Occam's razor)

   这其实是自然科学研究中的最基本原则.意思是如果有多种办法都可以实现我们的目标，那么选其中最简单的那个.

2. 没有免费的午餐定理(NFL定理)

   该定理表明，脱离具体问题，空谈"什么学习算法更好"毫无意义.

# 2. 模型评估与选择

## 2.1 经验误差与过拟合

`错误率(error rate)`：分类错误的样本占样本总数的比例
`精度(accuracy)`: 分类正确的样本占样本总数的比例，即"精度 = 1 - 错误率"
`误差(error)`:学习器的实际预测输出与样本的真实输出之间的差异
`训练误差/经验误差(training error/empirical error)`: 学习器在训练集上的误差
`泛化误差(generalization error)`: 学习器在新样本上的误差
`过拟合`：
`欠拟合`：

## 2.2 评估方法

若测试样本用于学习器的学习，则会产生过拟合问题.因此，可以通过对训练集D进行再次的划分，产生新的训练集S和测试集T.

### 2.2.1 留出法

留出法(hold out)直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T(一般将大约$\frac{2}{3}$~$\frac{4}{5}$的样本用于训练，其余样本用于测试)

**注意：**

- 训练集/测试集的划分要尽可能保持数据分布的一致性
- 单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随即划分，重复进行实验评估后取平均值作为留出法的评估结果

### 2.2.2 交叉验证法

交叉验证法(cross validation)先将数据集D划分为k各大小相似的互斥子集，即$D=D_1\bigcup D_2\bigcup ...\bigcup D_k$.每个子集$D_i$都尽可能保持数据分布一致性.然后，每次用$k-1$个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练/测试集，从而可以进行k次训练和测试，最终返回的是这k个测试结果的均值.显然，`交叉验证法的评估结果的稳定性和保真性在很大程度上取决于k的取值`，因此交叉验证法通常称为`k折交叉验证(k-fold)`

### 2.2.3 自助法

在留出法和交叉验证中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这样必然会引入一些因训练样本规模不同而导致的估计偏差.留一法受训练样本规模变化较小，但计算复杂度较高。

自助法(bootstrapping): 给定包含m个样本的数据集D，对他进行采样产生数据集$D'$，每次随机从D中有放回选择一个样本放入$D'$中，重复执行m次，就得到了包含m个样本的数据集$D'$.样本在m次采样中始终不被取到的概率去极限得到：
$$
\lim_{m\rightarrow ∞}(1 - \frac{1}{m})^m ≈ 0.368
$$
然后，我们可以将$D'$用作训练集，$D/D'$用作测试集.

自助法适用于数据集较小，难以有效划分训练/测试集的情况，并且自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。

## 2.3 性能度量

回归任务最常用的性能度量是`均方误差(MSE)`:
$$
E(f;D)=\frac{1}{m}\sum_{i = 1}^{m}(f(x_i) - y_i)^2
$$
对于数据分布$D$和概率密度函数$p(x)$, MSE可表述为：
$$
E(f;D)=\frac{1}{m}\int_{x～D}(f(x_i) - y_i)^2p(x)dx
$$

### 2.3.1 错误率与精度

### 2.3.2 查准率，查全率与F1

1. **混淆矩阵（Confuse Matrix）**  

![image-20210803152721771](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/image-20210803152721771.png)



2. **查准率P(Precision):**
$$
P = \frac{TP}{TP + FP}
$$
3. **查全率R(Recall):**
$$
R = \frac{TP}{TP + FN}
$$
4. **P-R曲线（Precision-Recall Curve）**
`P-R曲线`是描述精确率和召回率变化的曲线，如下图所示：
![20200913131448921](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/20200913131448921.png)
> 现实任务中的P-R曲线常常是非单调，不平滑的，在很多局部都有上下波动

很多情况下，可以根据学习器的预测结果对样例进行排序，排名越靠前，则是正例的可能性越大。`按此顺序依次选择样例，将该样本之前的设为正例，该样本之后的设为负例`，则每次可以计算出当前的查准率与查全率，从而得到了`P-R曲线`

P-R曲线如何评估呢？若一个学习器B的P-R曲线被另一个学习器A的P-R曲线完全包住，则称：A的性能优于B。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“平衡点”（Break-Event Point，简称BEP），即当P=R时的取值，平衡点的取值越高，性能更优。

5. **F1度量**
$$
F1 = \frac{2×P×R}{P + R}
$$
在一些应用中，对P和R的重视程度有所不同，因此，给出F1的一般形式：$F_\beta$
$$
F_\beta = \frac{(1 + \beta^2)×P×R}{(\beta^2×P) + R}
$$
其中$\beta>0$度量了查准率对查全率的相对重要性，$\beta = 1$ 时退化为$F1$，$\beta > 1$时查全率有更大影响，$\beta < 1$时查准率有更大影响。

当有多个混肴矩阵时：
- 在各混肴矩阵上分别计算出查准率和查全率，在计算平均值，这样就得到`macro-P`, `macro-R`, `macro-F1`
$$
macro-P = \frac{1}{n}\sum_{i = 1}^nP_i\\
macro-R = \frac{1}{n}\sum_{i = 1}^nR_i\\
macro-F1 = \frac{2\times macro-P \times macro-R}{macro-P + macro-R}
$$
- 先将各混肴矩阵各元素进行平均，得到$\overline{TP}$，$\overline{FP}$，$\overline{TN}$，$\overline{FN}$，然后计算`micro-P`, `micro-R`, `micro-F1`

$$
micro-P = \frac{\overline{TP}}{\overline{TP} + \overline{FP}}\\
micro-R = \frac{\overline{TP}}{\overline{TP} + \overline{FN}}\\
micro-F1 = \frac{2\times micro-P \times micro-R}{micro-P + micro-R}
$$



### 2.3.3 ROC与AUC

**ROC曲线**：接收者操作特征（receiver operating characteristic），ROC曲线上每个点反映着对同一信号刺激的感受性。该曲线最早应用于雷达信号检测领域，用于区分信号与噪声。后来人们将其用于评价模型的预测能力。

横轴：负正类率（FPR，特异度）: $\frac{TP}{TP + FN}$
纵轴：真正类率（TPR，灵敏度）: $\frac{FP}{TN + FP}$

**AUC曲线**（Area Under ROC Curve），AUC被定义为 ROC曲线 下与坐标轴围成的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。AUC越接近1.0，检测方法真实性越高；等于0.5时，则真实性最低，无应用价值。

### 2.3.4 代价敏感错误率与代价曲线

## 2.4 比较检验

### 2.4.1 假设检验

### 2.4.2 交叉验证t检验

### 2.4.3 McNemar检验

### 2.4.4 Friedman检验与Nemenyi后续检验

1. **Friedman检验**
对于*k*个算法和*N*个数据集，首先得到每个算法在每个数据集上的测试性能结果，然后根据性能结果有好到坏排序，并给出序值1, 2, …, k，若多个算法性能结果相同，则它们平分序值，假设第*i*个算法的平均序值为$r_i$：

![img](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/20190806210117580.png)

![img](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/20190806210121867.png)

2. **Nemenyi检验**
Nemenyi检验计算出平均序值差别的临界值域*CD*:

![img](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/20190806210411246.png)

​	$q_\alpha$的值可以查看下表获得：

![img](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/20190806210510458.png)

​	如果任意两个算法的序值差大于*CD*，则这两个算法性能有明显差异。

![image-20210803152158578](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/image-20210803152158578.png)



## 2.5 偏差与方差

# 3. 线性模型

## 3.1 一元线性回归

# 4. 决策树

## 4.1 ID3

ID3以信息增益为划分的准则

`信息熵(information entropy)`是度量样本集合纯度的指标，假定当前样本集合D中第k类样本所占的比例为$p_k(k=1, 2...|y|)$，则D的信息熵定义为
$$
Ent(D) = -\sum_{k=1}^{y}p_k\log_2p_k
$$
$Ent(D)$的值越小，D的纯度越高

`信息增益(information gain)`定义为：
$$
Gain(D, a) = Ent(D) - \sum_{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v)
$$
一般而言，信息增益越大，意味着使用属性a来进行划分所获得的纯度提升越大

## 4.2 C4.5

C4.5以增益率为划分的准则

信息增益准则对可取值数目较多的属性有所偏好，增益率可以减少这种偏好可能带来的不利影响。

`增益率(gain ratio)`定义为：
$$
Gain_ratio(D, a) = \frac{Gain(D, a)}{IV(a)}, 其中\\
IV(a) = -\sum_{v = 1}^{V}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}
$$
IV(a)称为属性a的`固有值(intrinsic value)`，属性a的可能取值越多，IV(a)的值越大。增益率对可取值数目较少的属性有所偏好，因此，C4.5算法使用了一种启发式方法，先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的

## 4.3 CART

使用基尼指数来作为划分的准则

`基尼指数(Gini index)`定义为：
$$
Gini(D) = \sum_{k = 1}^{|y|}\sum_{k' \neq k}p_kp_{k'} = 1 - \sum_{k=1}^{|y|}p_{k}^2
$$
基尼指数反映了从数据集 D中随机抽取两个样本，其类别标记不一致的概率，因此，基尼指数越小，数据集D的纯度越高

属性a的基尼指数定义为：
$$
Gini\_index(D, a) = \sum_{v=1}^V\frac{|D^v|}{|D|}Gini(D^v)
$$
因此，我们在候选属性集合A中，选择使得划分后基尼指数最小的属性作为最优划分集，即$a_* = \arg_{a\in A}min~Gini\_index(D, a)$

## 4.4 剪枝处理

### 4.4.1 预剪枝(prepruning)

预剪枝是指在决策树生成过程中，对每个结点在划分前进行估计，若当前节点的划分不能带来决策树泛化性能的提升，则停止划分并将当前节点标记为叶节点。

预剪枝使得决策树的很多分支都没有展开，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间和测试时间的开销.但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高;预剪枝基于"贪心"本质禁止这些分支展开给预剪枝决策树带来了欠拟含的风险。

### 4.4.2 后剪枝(post-pruning)

后剪枝则是先从训练集生成一颗完整的决策树，然后自底向上的对非叶节点进行考察，若将该节点对应的子树替换为叶节点能带来决策树泛化性能的提升，则将该子树替换为叶节点。

后剪枝决策树通常比预剪枝决策树保留了更多的分支，一般情形下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树.但后剪枝过程是在生成完全决策树之后进行的 并且要自底向上对树中的所有非叶结点进行逐个考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。

# 5. 神经网络

神经网络是具有适应性的简单单元组成的广泛并行互联的网络，他的组织能够模拟生物神经系统对真实世界所作出的交互反应

## 5.1 M-P神经元模型

<img src="http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/image-20210803093335912.png">

## 5.2 感知机

感知机由两层神经元组成，输入层接受外界输入信号后传递给输出层，输出层是M-P神经元

![image-20210803093559734](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/image-20210803093559734.png)

## 5.3 神经网络

感知机这种单个神经元分类能力有限，只能分类线性可分的数据集，但是多个神经元构成的神经网路能够分类线性不可分的数据集。

### 5.3.1 多层前馈网络

每层神经元与下一层神经元全连接，神经元之间不存在同层连接，也不存在跨层连接（又称全连接神经网络-fc）

![image-20210803105438719](http://lhapy-typora-image.oss-cn-beijing.aliyuncs.com/img/image-20210803105438719.png)

### 5.3.2 误差逆传播算法

`误差逆传播(error BackPropagation, 简称BP)`,即反向传播，目标是最小化训练集D上的积累误差，BP算法基于梯度下降策略(gradient descent),以目标的负梯度方向对梯度进行调整。

BP算法的目标是要最小化训练集D上的累计误差：
$$
E = \frac{1}{m}\sum_{k=1}^mE_k
$$


“标准BP算法”每次仅针对一个训练样例更新连接权和阈值，每次更新只针对单个样例，参数更新较频繁。而“累积BP算法”直接针对累计误差进行最小化，在读取整个数据集一遍之后才对参数进行更新，其参数更新频率会低得多。

BP神经网络通常会出现过拟合的现象。有两种策略：

- 早停(early-stopping): 将参数分成训练集和验证集，训练集用来计算梯度，更新权值和阈值；验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。
- 正则化(regulization): 在误差目标函数中增加一个用于描述网络复杂程度的部分，例如连接权和阈值的平方和。









# 13 半监督学习